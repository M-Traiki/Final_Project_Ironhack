{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bffde39",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "This notebook loads the preprocessed shot data, trains several xG models (with and without geometry features), and evaluates them against actual goals and the StatsBomb xG values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c59508",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dcd346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313b8d39",
   "metadata": {},
   "source": [
    "## Load preprocessed shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be474653",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"shots_featured_wc2018.csv\")\n",
    "shots_featured = pd.read_csv(data_path)\n",
    "shots_featured.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d21178",
   "metadata": {},
   "source": [
    "## Define target and feature sets\n",
    "\n",
    "We keep `shot_statsbomb_xg` and `is_goal` for evaluation. We build two feature matrices:\n",
    "\n",
    "- **Raw features** (`X_raw`): all features *except* distance and angle (this mimics your early models).\n",
    "- **Featured geometry** (`X_feat`): all features including distance and angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871ac12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "y = shots_featured[\"is_goal\"].astype(int)\n",
    "\n",
    "# Base feature set (drop labels/statsbomb xg)\n",
    "X_full = shots_featured.drop([\"shot_statsbomb_xg\", \"is_goal\"], axis=1)\n",
    "\n",
    "# Raw features: no distance & angle\n",
    "drop_geom = [col for col in [\"distance\", \"angle\"] if col in X_full.columns]\n",
    "X_raw = X_full.drop(drop_geom, axis=1)\n",
    "\n",
    "# Featured geometry = all features\n",
    "X_feat = X_full.copy()\n",
    "\n",
    "X_raw.head(), X_feat.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164ef892",
   "metadata": {},
   "source": [
    "## Train/test split (shared indices)\n",
    "\n",
    "We split once using `X_feat` and `y`, then use the resulting indices to build matching train/test sets for `X_raw`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55023ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_feat, X_test_feat, y_train, y_test = train_test_split(\n",
    "    X_feat, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Align raw feature splits using the same indices\n",
    "X_train_raw = X_raw.loc[X_train_feat.index]\n",
    "X_test_raw = X_raw.loc[X_test_feat.index]\n",
    "\n",
    "X_train_feat.shape, X_train_raw.shape, X_test_feat.shape, X_test_raw.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b720505",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression (raw features, no geometry)\n",
    "\n",
    "This corresponds to your early logistic regression model based on x, y and categorical/boolean features, but without distance and angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0767200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_raw = LogisticRegression(max_iter=2000)\n",
    "lr_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "lr_raw_pred_train = lr_raw.predict_proba(X_train_raw)[:, 1]\n",
    "lr_raw_pred_test = lr_raw.predict_proba(X_test_raw)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a6365",
   "metadata": {},
   "source": [
    "## 2. XGBoost (raw features, no geometry)\n",
    "\n",
    "This is the analogue of your strong early XGBoost model that only used raw coordinates and simple features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfca4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_raw = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "\n",
    "xgb_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "xgb_raw_pred_train = xgb_raw.predict_proba(X_train_raw)[:, 1]\n",
    "xgb_raw_pred_test = xgb_raw.predict_proba(X_test_raw)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79b84f",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression (featured geometry, unscaled)\n",
    "\n",
    "This corresponds to your `lr_featured` model: distance and angle included, but no scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65790177",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_featured = LogisticRegression(max_iter=2000)\n",
    "lr_featured.fit(X_train_feat, y_train)\n",
    "\n",
    "lr_featured_pred_train = lr_featured.predict_proba(X_train_feat)[:, 1]\n",
    "lr_featured_pred_test = lr_featured.predict_proba(X_test_feat)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f45ec4",
   "metadata": {},
   "source": [
    "## 4. XGBoost (featured geometry)\n",
    "\n",
    "This corresponds to your `xgb_featured` model that uses distance and angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94b003",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_featured = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\",\n",
    ")\n",
    "\n",
    "xgb_featured.fit(X_train_feat, y_train)\n",
    "\n",
    "xgb_featured_pred_train = xgb_featured.predict_proba(X_train_feat)[:, 1]\n",
    "xgb_featured_pred_test = xgb_featured.predict_proba(X_test_feat)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5722ca",
   "metadata": {},
   "source": [
    "## 5. Scaled Logistic Regression (featured geometry)\n",
    "\n",
    "We standardize all features and then fit logistic regression. This corresponds to your `lr_scaled` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7ef36",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_feat)\n",
    "X_test_scaled = scaler.transform(X_test_feat)\n",
    "\n",
    "lr_scaled = LogisticRegression(max_iter=2000)\n",
    "lr_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_scaled_pred_train = lr_scaled.predict_proba(X_train_scaled)[:, 1]\n",
    "lr_scaled_pred_test = lr_scaled.predict_proba(X_test_scaled)[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92635b08",
   "metadata": {},
   "source": [
    "## Build comparison dataframe (test set)\n",
    "\n",
    "We collect StatsBomb xG, actual goals, and predictions from all five models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89474a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame({\n",
    "    \"shot_statsbomb_xg\": shots_featured.loc[X_test_feat.index, \"shot_statsbomb_xg\"].values,\n",
    "    \"is_goal\": y_test.values,\n",
    "    \"lr_raw\": lr_raw_pred_test,\n",
    "    \"xgb_raw\": xgb_raw_pred_test,\n",
    "    \"lr_featured\": lr_featured_pred_test,\n",
    "    \"xgb_featured\": xgb_featured_pred_test,\n",
    "    \"lr_scaled\": lr_scaled_pred_test,\n",
    "})\n",
    "\n",
    "comparison_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9095ea97",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5dfe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbc6c17",
   "metadata": {},
   "source": [
    "## Total xG vs actual goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33f2557",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual goals (test):\", comparison_df[\"is_goal\"].sum())\n",
    "print(\"StatsBomb total xG (test):\", comparison_df[\"shot_statsbomb_xg\"].sum())\n",
    "print(\"LR raw total xG (test):\", comparison_df[\"lr_raw\"].sum())\n",
    "print(\"XGB raw total xG (test):\", comparison_df[\"xgb_raw\"].sum())\n",
    "print(\"LR featured total xG (test):\", comparison_df[\"lr_featured\"].sum())\n",
    "print(\"XGB featured total xG (test):\", comparison_df[\"xgb_featured\"].sum())\n",
    "print(\"LR scaled total xG (test):\", comparison_df[\"lr_scaled\"].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c5c80",
   "metadata": {},
   "source": [
    "## Correlation with StatsBomb xG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_df[[\n",
    "    \"shot_statsbomb_xg\",\n",
    "    \"lr_raw\",\n",
    "    \"xgb_raw\",\n",
    "    \"lr_featured\",\n",
    "    \"xgb_featured\",\n",
    "    \"lr_scaled\",\n",
    "]].corr()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753e89b",
   "metadata": {},
   "source": [
    "## AUC and Brier scores vs actual goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad34ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_lr_raw = roc_auc_score(comparison_df[\"is_goal\"], comparison_df[\"lr_raw\"])\n",
    "auc_xgb_raw = roc_auc_score(comparison_df[\"is_goal\"], comparison_df[\"xgb_raw\"])\n",
    "auc_lr_featured = roc_auc_score(comparison_df[\"is_goal\"], comparison_df[\"lr_featured\"])\n",
    "auc_xgb_featured = roc_auc_score(comparison_df[\"is_goal\"], comparison_df[\"xgb_featured\"])\n",
    "auc_lr_scaled = roc_auc_score(comparison_df[\"is_goal\"], comparison_df[\"lr_scaled\"])\n",
    "\n",
    "brier_lr_raw = brier_score_loss(comparison_df[\"is_goal\"], comparison_df[\"lr_raw\"])\n",
    "brier_xgb_raw = brier_score_loss(comparison_df[\"is_goal\"], comparison_df[\"xgb_raw\"])\n",
    "brier_lr_featured = brier_score_loss(comparison_df[\"is_goal\"], comparison_df[\"lr_featured\"])\n",
    "brier_xgb_featured = brier_score_loss(comparison_df[\"is_goal\"], comparison_df[\"xgb_featured\"])\n",
    "brier_lr_scaled = brier_score_loss(comparison_df[\"is_goal\"], comparison_df[\"lr_scaled\"])\n",
    "\n",
    "print(\"=== AUC ===\")\n",
    "print(\"LR raw:       \", auc_lr_raw)\n",
    "print(\"XGB raw:      \", auc_xgb_raw)\n",
    "print(\"LR featured:  \", auc_lr_featured)\n",
    "print(\"XGB featured: \", auc_xgb_featured)\n",
    "print(\"LR scaled:    \", auc_lr_scaled)\n",
    "\n",
    "print(\"\\n=== Brier ===\")\n",
    "print(\"LR raw:       \", brier_lr_raw)\n",
    "print(\"XGB raw:      \", brier_xgb_raw)\n",
    "print(\"LR featured:  \", brier_lr_featured)\n",
    "print(\"XGB featured: \", brier_xgb_featured)\n",
    "print(\"LR scaled:    \", brier_lr_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef207d7",
   "metadata": {},
   "source": [
    "## Scatterplots vs StatsBomb xG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e044f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharex=True, sharey=True)\n",
    "\n",
    "axes[0].scatter(comparison_df[\"shot_statsbomb_xg\"], comparison_df[\"lr_raw\"], alpha=0.3)\n",
    "axes[0].set_title(\"LR raw vs StatsBomb\")\n",
    "axes[0].set_xlabel(\"StatsBomb xG\")\n",
    "axes[0].set_ylabel(\"Model xG\")\n",
    "\n",
    "axes[1].scatter(comparison_df[\"shot_statsbomb_xg\"], comparison_df[\"xgb_raw\"], alpha=0.3)\n",
    "axes[1].set_title(\"XGB raw vs StatsBomb\")\n",
    "axes[1].set_xlabel(\"StatsBomb xG\")\n",
    "\n",
    "axes[2].scatter(comparison_df[\"shot_statsbomb_xg\"], comparison_df[\"xgb_featured\"], alpha=0.3)\n",
    "axes[2].set_title(\"XGB featured vs StatsBomb\")\n",
    "axes[2].set_xlabel(\"StatsBomb xG\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d11164",
   "metadata": {},
   "source": [
    "## (Optional) Save models to disk\n",
    "\n",
    "Uncomment and run this cell if you want to persist the trained models and scaler as `.pkl` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(lr_raw, \"lr_raw_wc2018.pkl\")\n",
    "# joblib.dump(xgb_raw, \"xgb_raw_wc2018.pkl\")\n",
    "# joblib.dump(lr_featured, \"lr_featured_wc2018.pkl\")\n",
    "# joblib.dump(xgb_featured, \"xgb_featured_wc2018.pkl\")\n",
    "# joblib.dump(lr_scaled, \"lr_scaled_wc2018.pkl\")\n",
    "# joblib.dump(scaler, \"scaler_wc2018.pkl\")\n",
    "# print(\"Saved models and scaler to disk.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
